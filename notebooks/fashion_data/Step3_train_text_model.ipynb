{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the third step of this tutorial, we will train an text model. This notebook can be run in parallel with Step 2 (training the image model). A lof of the cells in this notebook are similar to the previous one.\n",
    "\n",
    "This notebook was run on an AWS p3.2xlarge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Octopod Text Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, BertTokenizer, get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for text, we use the MultiTaskLearner since we will only have one input, the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octopod import MultiTaskLearner, MultiDatasetLoader\n",
    "from octopod.text.dataset import OctopodTextDataset\n",
    "from octopod.text.models.multi_task_bert import BertForMultiTaskClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our Bert model, we need a tokenizer. We'll use the one from huggingface's `transformers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tok = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in train and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load in the csv's we created in Step 1.\n",
    "Remember to change the path if you stored your data somewhere other than the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_GENDER_DF = pd.read_csv('/home/ubuntu/fashion_dataset/gender_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_GENDER_DF = pd.read_csv('/home/ubuntu/fashion_dataset/gender_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SEASON_DF = pd.read_csv('/home/ubuntu/fashion_dataset/season_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_SEASON_DF = pd.read_csv('/home/ubuntu/fashion_dataset/season_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will most likely have to alter this to however big your batches can be on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `OctopodTextDataSet` class to create train and valid datasets for each task.\n",
    "\n",
    "Check out the documentation for infomation about the `tokenizer` and `max_seq_length` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_train_dataset = OctopodTextDataset(\n",
    "    x=TRAIN_GENDER_DF['productDisplayName'],\n",
    "    y=TRAIN_GENDER_DF['gender_cat'],\n",
    "    tokenizer=bert_tok,\n",
    "    max_seq_length=max_seq_length\n",
    ")\n",
    "gender_valid_dataset = OctopodTextDataset(\n",
    "    x=VALID_GENDER_DF['productDisplayName'],\n",
    "    y=VALID_GENDER_DF['gender_cat'],\n",
    "    tokenizer=bert_tok,\n",
    "    max_seq_length=max_seq_length\n",
    ")\n",
    "\n",
    "season_train_dataset = OctopodTextDataset(\n",
    "    x=TRAIN_SEASON_DF['productDisplayName'],\n",
    "    y=TRAIN_SEASON_DF['season_cat'],\n",
    "    tokenizer=bert_tok,\n",
    "    max_seq_length=max_seq_length\n",
    ")\n",
    "season_valid_dataset = OctopodTextDataset(\n",
    "    x=VALID_SEASON_DF['productDisplayName'],\n",
    "    y=VALID_SEASON_DF['season_cat'],\n",
    "    tokenizer=bert_tok,\n",
    "    max_seq_length=max_seq_length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then put the datasets into a dictionary of dataloaders.\n",
    "\n",
    "Each task is a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloaders_dict = {\n",
    "    'gender': DataLoader(gender_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "    'season': DataLoader(season_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "}\n",
    "valid_dataloaders_dict = {\n",
    "    'gender': DataLoader(gender_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4),\n",
    "    'season': DataLoader(season_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary of dataloaders is then put into an instance of the Octopod `MultiDatasetLoader` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLoader = MultiDatasetLoader(loader_dict=train_dataloaders_dict)\n",
    "len(TrainLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValidLoader = MultiDatasetLoader(loader_dict=valid_dataloaders_dict, shuffle=False)\n",
    "len(ValidLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a dictionary of the tasks and the number of unique values so that we can create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_task_dict = {\n",
    "    'gender': TRAIN_GENDER_DF['gender_cat'].nunique(),\n",
    "    'season': TRAIN_SEASON_DF['season_cat'].nunique(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': 5, 'season': 4}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_task_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model and Learner\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are completely new tasks so we use `new_task_dict`. If we had already trained a model on some tasks, we would use `pretrained_task_dict`.\n",
    "\n",
    "We are using the trained bert weights from the `transformers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMultiTaskClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    new_task_dict=new_task_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will likely need to explore different values in this section to find some that work\n",
    "for your particular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 1e-5\n",
    "num_total_steps = len(TrainLoader)\n",
    "num_warmup_steps = int(len(TrainLoader) * 0.1)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=True)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = MultiTaskLearner(model, TrainLoader, ValidLoader, new_task_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your model trains, you can see some output of how the model is performing overall and how it is doing on each individual task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>gender_train_loss</th>\n",
       "      <th>gender_val_loss</th>\n",
       "      <th>gender_acc</th>\n",
       "      <th>season_train_loss</th>\n",
       "      <th>season_val_loss</th>\n",
       "      <th>season_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1.443156</td>\n",
       "      <td>1.436217</td>\n",
       "      <td>1.496199</td>\n",
       "      <td>1.494172</td>\n",
       "      <td>0.420691</td>\n",
       "      <td>1.372393</td>\n",
       "      <td>1.358906</td>\n",
       "      <td>0.188317</td>\n",
       "      <td>06:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.262111</td>\n",
       "      <td>1.149637</td>\n",
       "      <td>1.245156</td>\n",
       "      <td>1.084975</td>\n",
       "      <td>0.495216</td>\n",
       "      <td>1.284731</td>\n",
       "      <td>1.235895</td>\n",
       "      <td>0.483706</td>\n",
       "      <td>06:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.017829</td>\n",
       "      <td>0.889183</td>\n",
       "      <td>0.865197</td>\n",
       "      <td>0.652203</td>\n",
       "      <td>0.849263</td>\n",
       "      <td>1.221454</td>\n",
       "      <td>1.205311</td>\n",
       "      <td>0.483706</td>\n",
       "      <td>06:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.782725</td>\n",
       "      <td>0.708237</td>\n",
       "      <td>0.472487</td>\n",
       "      <td>0.352095</td>\n",
       "      <td>0.906788</td>\n",
       "      <td>1.196609</td>\n",
       "      <td>1.183323</td>\n",
       "      <td>0.483706</td>\n",
       "      <td>06:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.674205</td>\n",
       "      <td>0.647238</td>\n",
       "      <td>0.297471</td>\n",
       "      <td>0.255677</td>\n",
       "      <td>0.946077</td>\n",
       "      <td>1.176801</td>\n",
       "      <td>1.169574</td>\n",
       "      <td>0.483706</td>\n",
       "      <td>06:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.615526</td>\n",
       "      <td>0.594338</td>\n",
       "      <td>0.204330</td>\n",
       "      <td>0.173638</td>\n",
       "      <td>0.953282</td>\n",
       "      <td>1.164096</td>\n",
       "      <td>1.155545</td>\n",
       "      <td>0.483706</td>\n",
       "      <td>06:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.572668</td>\n",
       "      <td>0.555147</td>\n",
       "      <td>0.141206</td>\n",
       "      <td>0.117855</td>\n",
       "      <td>0.980525</td>\n",
       "      <td>1.148274</td>\n",
       "      <td>1.138487</td>\n",
       "      <td>0.483706</td>\n",
       "      <td>06:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.545199</td>\n",
       "      <td>0.528069</td>\n",
       "      <td>0.107176</td>\n",
       "      <td>0.091960</td>\n",
       "      <td>0.982664</td>\n",
       "      <td>1.129557</td>\n",
       "      <td>1.109831</td>\n",
       "      <td>0.511188</td>\n",
       "      <td>06:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.509614</td>\n",
       "      <td>0.505068</td>\n",
       "      <td>0.088725</td>\n",
       "      <td>0.081082</td>\n",
       "      <td>0.984465</td>\n",
       "      <td>1.071116</td>\n",
       "      <td>1.070659</td>\n",
       "      <td>0.524103</td>\n",
       "      <td>06:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.464816</td>\n",
       "      <td>0.494566</td>\n",
       "      <td>0.075624</td>\n",
       "      <td>0.072447</td>\n",
       "      <td>0.987279</td>\n",
       "      <td>0.984032</td>\n",
       "      <td>1.057667</td>\n",
       "      <td>0.525304</td>\n",
       "      <td>06:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 best model saved with loss of 0.49456640841227717\n"
     ]
    }
   ],
   "source": [
    "learn.fit(\n",
    "    num_epochs=10,\n",
    "    loss_function=loss_function,\n",
    "    scheduler=scheduler,\n",
    "    step_scheduler_on_batch=False,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    best_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate Model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a method on the learner called `get_val_preds`, which makes predictions on the validation data. You can then use this to analyze your model's performance in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = learn.get_val_preds(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': {'y_true': array([0., 2., 4., ..., 4., 2., 2.]),\n",
       "  'y_pred': array([[0.74698263, 0.10318641, 0.08654781, 0.03519604, 0.02808712],\n",
       "         [0.00239562, 0.00217793, 0.99014109, 0.00213638, 0.00314901],\n",
       "         [0.00328295, 0.00526687, 0.00393449, 0.00815226, 0.97936338],\n",
       "         ...,\n",
       "         [0.00183818, 0.00299671, 0.00261172, 0.00342717, 0.98912621],\n",
       "         [0.01128249, 0.00917029, 0.95130181, 0.01607285, 0.01217249],\n",
       "         [0.00264054, 0.00205473, 0.98852623, 0.00422364, 0.00255485]])},\n",
       " 'season': {'y_true': array([0., 0., 2., ..., 2., 3., 3.]),\n",
       "  'y_pred': array([[0.20209727, 0.06460249, 0.37908569, 0.35421461],\n",
       "         [0.2017833 , 0.06096645, 0.42957458, 0.30767566],\n",
       "         [0.1913355 , 0.06862341, 0.3871206 , 0.35292041],\n",
       "         ...,\n",
       "         [0.16365369, 0.06352966, 0.36214185, 0.41067481],\n",
       "         [0.10442591, 0.05663429, 0.08722814, 0.75171155],\n",
       "         [0.05810045, 0.06206312, 0.0734309 , 0.80640548]])}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/Export Model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are happy with our training we can save (or export) our model, using the `save` method (or `export`).\n",
    "\n",
    "See the docs for the difference between `save` and `export`.\n",
    "\n",
    "We will need the saved model later to use in the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(folder='/home/ubuntu/fashion_dataset/models/', model_id='TEXT_MODEL1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(folder='/home/ubuntu/fashion_dataset/models/', model_id='TEXT_MODEL1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an image model and a text model, we can move to `Step4_train_ensemble_model`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
