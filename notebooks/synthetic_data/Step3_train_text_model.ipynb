{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the third step of this tutorial, we will train a text model. This step can be run in parallel with Step 2 (training the image model).\n",
    "\n",
    "This notebook was run on an AWS p3.2xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tonks Text Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, BertTokenizer, get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for text, we use the MultiTaskLearner since we will only have one input, the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tonks import MultiTaskLearner, MultiDatasetLoader\n",
    "from tonks.text.dataset import TonksTextDataset\n",
    "from tonks.text.models.multi_task_bert import BertForMultiTaskClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our Bert model, we need a tokenizer. We'll use the one from huggingface's `transformers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tok = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in train and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load in the csv's we created in Step 1.\n",
    "Remember to change the path if you stored your data somewhere other than the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_COLOR_DF = pd.read_csv('data/color_swatches/color_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_COLOR_DF = pd.read_csv('data/color_swatches/color_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATTERN_DF = pd.read_csv('data/pattern_swatches/pattern_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_PATTERN_DF = pd.read_csv('data/pattern_swatches/pattern_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will most likely have to alter this to however big your batches can be on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `TonksTextDataSet` class to create train and valid datasets for each task.\n",
    "\n",
    "Check out the documentation for infomation about the `tokenizer` and `max_seq_length` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_train_dataset = TonksTextDataset(\n",
    "    x=TRAIN_COLOR_DF['complex_color'],\n",
    "    y=TRAIN_COLOR_DF['simple_color_cat'],\n",
    "    tokenizer=bert_tok,\n",
    "    max_seq_length=max_seq_length\n",
    ")\n",
    "color_valid_dataset = TonksTextDataset(\n",
    "    x=VALID_COLOR_DF['complex_color'],\n",
    "    y=VALID_COLOR_DF['simple_color_cat'],\n",
    "    tokenizer=bert_tok,\n",
    "    max_seq_length=max_seq_length\n",
    ")\n",
    "\n",
    "pattern_train_dataset = TonksTextDataset(\n",
    "    x=TRAIN_PATTERN_DF['fake_text'],\n",
    "    y=TRAIN_PATTERN_DF['pattern_type_cat'],\n",
    "    tokenizer=bert_tok,\n",
    "    max_seq_length=max_seq_length\n",
    ")\n",
    "pattern_valid_dataset = TonksTextDataset(\n",
    "    x=VALID_PATTERN_DF['fake_text'],\n",
    "    y=VALID_PATTERN_DF['pattern_type_cat'],\n",
    "    tokenizer=bert_tok,\n",
    "    max_seq_length=max_seq_length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then put the datasets into a dictionary of dataloaders.\n",
    "\n",
    "Each task is a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloaders_dict = {\n",
    "    'color': DataLoader(color_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2),\n",
    "    'pattern': DataLoader(pattern_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2),\n",
    "}\n",
    "valid_dataloaders_dict = {\n",
    "    'color': DataLoader(color_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2),\n",
    "    'pattern': DataLoader(pattern_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary of dataloaders is then put into an instance of the Tonks `MultiDatasetLoader` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLoader = MultiDatasetLoader(loader_dict=train_dataloaders_dict)\n",
    "len(TrainLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValidLoader = MultiDatasetLoader(loader_dict=valid_dataloaders_dict, shuffle=False)\n",
    "len(ValidLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a dictionary of the tasks and the number of unique values so that we can create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_task_dict = {\n",
    "    'color': TRAIN_COLOR_DF['simple_color_cat'].nunique(),\n",
    "    'pattern': TRAIN_PATTERN_DF['pattern_type_cat'].nunique(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'color': 2, 'pattern': 2}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_task_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model and Learner\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are completely new tasks so we use `new_task_dict`. If we had already trained a model on some tasks, we would use `pretrained_task_dict`.\n",
    "\n",
    "We are using the trained bert weights from the `transformers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMultiTaskClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    new_task_dict=new_task_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will likely need to explore different values in this section to find some that work\n",
    "for your particular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "num_total_steps = len(TrainLoader)\n",
    "num_warmup_steps = int(len(TrainLoader) * 0.1)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=True)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function_dict = {'color': 'categorical_cross_entropy', 'pattern': 'categorical_cross_entropy'}\n",
    "metric_function_dict = {'color': 'multi_class_acc', 'pattern': 'multi_class_acc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = MultiTaskLearner(model, TrainLoader, ValidLoader, new_task_dict, loss_function_dict, metric_function_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your model trains, you can see some output of how the model is performing overall and how it is doing on each individual task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>color_train_loss</th>\n",
       "      <th>color_val_loss</th>\n",
       "      <th>color_multi_class_accuracy</th>\n",
       "      <th>pattern_train_loss</th>\n",
       "      <th>pattern_val_loss</th>\n",
       "      <th>pattern_multi_class_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.778012</td>\n",
       "      <td>0.055968</td>\n",
       "      <td>0.783875</td>\n",
       "      <td>0.053472</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.752760</td>\n",
       "      <td>0.066747</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.674224</td>\n",
       "      <td>0.043690</td>\n",
       "      <td>0.665308</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.712620</td>\n",
       "      <td>0.055025</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.654346</td>\n",
       "      <td>0.043586</td>\n",
       "      <td>0.639745</td>\n",
       "      <td>0.040674</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.717229</td>\n",
       "      <td>0.056164</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.639385</td>\n",
       "      <td>0.042089</td>\n",
       "      <td>0.625564</td>\n",
       "      <td>0.038878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.698906</td>\n",
       "      <td>0.055960</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.570441</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>0.540157</td>\n",
       "      <td>0.025649</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.700864</td>\n",
       "      <td>0.055693</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.462992</td>\n",
       "      <td>0.029534</td>\n",
       "      <td>0.400440</td>\n",
       "      <td>0.023678</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.732381</td>\n",
       "      <td>0.054828</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.446936</td>\n",
       "      <td>0.027798</td>\n",
       "      <td>0.385667</td>\n",
       "      <td>0.021480</td>\n",
       "      <td>0.879630</td>\n",
       "      <td>0.710803</td>\n",
       "      <td>0.055090</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.374434</td>\n",
       "      <td>0.027564</td>\n",
       "      <td>0.307158</td>\n",
       "      <td>0.020976</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.664169</td>\n",
       "      <td>0.056023</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.322688</td>\n",
       "      <td>0.025514</td>\n",
       "      <td>0.238104</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>0.879630</td>\n",
       "      <td>0.686961</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.311871</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>0.221574</td>\n",
       "      <td>0.018499</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.700753</td>\n",
       "      <td>0.052108</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 best model saved with loss of 0.024816248565912247\n"
     ]
    }
   ],
   "source": [
    "learn.fit(\n",
    "    num_epochs=10,\n",
    "    scheduler=scheduler,\n",
    "    step_scheduler_on_batch=False,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    best_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate Model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a method on the learner called `get_val_preds`, which makes predictions on the validation data. You can then use this to analyze your model's performance in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_dict = learn.get_val_preds(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'color': {'y_true': array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "         0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "         1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "         0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]),\n",
       "  'y_pred': array([[0.04156319, 0.9584368 ],\n",
       "         [0.03864282, 0.96135724],\n",
       "         [0.13322338, 0.8667765 ],\n",
       "         [0.03779934, 0.9622007 ],\n",
       "         [0.04061379, 0.95938617],\n",
       "         [0.27278078, 0.7272193 ],\n",
       "         [0.04425954, 0.9557405 ],\n",
       "         [0.04093139, 0.95906866],\n",
       "         [0.8962909 , 0.10370906],\n",
       "         [0.09443904, 0.905561  ],\n",
       "         [0.8985974 , 0.10140265],\n",
       "         [0.8945364 , 0.1054636 ],\n",
       "         [0.04278225, 0.9572177 ],\n",
       "         [0.04270522, 0.9572948 ],\n",
       "         [0.8992177 , 0.10078228],\n",
       "         [0.06255517, 0.93744487],\n",
       "         [0.03747476, 0.96252525],\n",
       "         [0.04758653, 0.95241344],\n",
       "         [0.04210296, 0.957897  ],\n",
       "         [0.06503121, 0.93496877],\n",
       "         [0.04629923, 0.9537008 ],\n",
       "         [0.8844173 , 0.11558263],\n",
       "         [0.9032535 , 0.09674654],\n",
       "         [0.8996326 , 0.10036743],\n",
       "         [0.03548773, 0.9645122 ],\n",
       "         [0.04321041, 0.9567896 ],\n",
       "         [0.08409997, 0.9159001 ],\n",
       "         [0.8979529 , 0.10204706],\n",
       "         [0.32801992, 0.6719801 ],\n",
       "         [0.3796061 , 0.62039393],\n",
       "         [0.0447875 , 0.9552125 ],\n",
       "         [0.8806645 , 0.11933552],\n",
       "         [0.04057323, 0.95942676],\n",
       "         [0.90137076, 0.09862921],\n",
       "         [0.866746  , 0.133254  ],\n",
       "         [0.03977123, 0.96022874],\n",
       "         [0.03900165, 0.9609983 ],\n",
       "         [0.14406574, 0.8559343 ],\n",
       "         [0.12611482, 0.8738853 ],\n",
       "         [0.04542365, 0.9545764 ],\n",
       "         [0.04533339, 0.9546666 ],\n",
       "         [0.11386041, 0.88613963],\n",
       "         [0.8980296 , 0.10197031],\n",
       "         [0.03598542, 0.9640146 ],\n",
       "         [0.90041447, 0.09958551],\n",
       "         [0.8991412 , 0.10085879],\n",
       "         [0.89846516, 0.10153479],\n",
       "         [0.0391591 , 0.9608409 ],\n",
       "         [0.04088244, 0.95911753],\n",
       "         [0.04377052, 0.95622945],\n",
       "         [0.03609382, 0.9639062 ],\n",
       "         [0.04233113, 0.9576689 ],\n",
       "         [0.8999009 , 0.10009909],\n",
       "         [0.04065618, 0.95934385],\n",
       "         [0.04161485, 0.9583851 ],\n",
       "         [0.03799401, 0.96200603],\n",
       "         [0.04129681, 0.9587032 ],\n",
       "         [0.03808663, 0.96191335],\n",
       "         [0.043284  , 0.95671594],\n",
       "         [0.89892226, 0.10107771],\n",
       "         [0.9012588 , 0.09874118],\n",
       "         [0.03867641, 0.9613236 ],\n",
       "         [0.04186932, 0.9581306 ],\n",
       "         [0.8962096 , 0.1037904 ],\n",
       "         [0.890163  , 0.10983697],\n",
       "         [0.8973543 , 0.10264572],\n",
       "         [0.04081994, 0.95918006],\n",
       "         [0.0417227 , 0.9582773 ],\n",
       "         [0.03970911, 0.9602909 ],\n",
       "         [0.03775009, 0.96224993],\n",
       "         [0.8742136 , 0.12578644],\n",
       "         [0.90269536, 0.09730463],\n",
       "         [0.04325105, 0.9567489 ],\n",
       "         [0.90201366, 0.09798628],\n",
       "         [0.8966463 , 0.10335363],\n",
       "         [0.05255391, 0.9474461 ],\n",
       "         [0.7120473 , 0.28795275],\n",
       "         [0.04766249, 0.9523375 ],\n",
       "         [0.89564   , 0.10436001],\n",
       "         [0.19160634, 0.80839366],\n",
       "         [0.64293116, 0.3570688 ],\n",
       "         [0.05899078, 0.9410092 ],\n",
       "         [0.8995339 , 0.10046607],\n",
       "         [0.04095958, 0.95904046],\n",
       "         [0.04099961, 0.95900047],\n",
       "         [0.04053793, 0.9594621 ],\n",
       "         [0.04291065, 0.95708936],\n",
       "         [0.04062835, 0.9593717 ],\n",
       "         [0.89169025, 0.10830973],\n",
       "         [0.04354987, 0.9564501 ],\n",
       "         [0.90154815, 0.09845187],\n",
       "         [0.8964569 , 0.10354313],\n",
       "         [0.9010206 , 0.09897938],\n",
       "         [0.84406847, 0.15593155],\n",
       "         [0.03967369, 0.9603263 ],\n",
       "         [0.04485105, 0.95514894],\n",
       "         [0.05067294, 0.94932705],\n",
       "         [0.15154967, 0.8484503 ],\n",
       "         [0.12581842, 0.87418157],\n",
       "         [0.9005007 , 0.09949931],\n",
       "         [0.0421296 , 0.9578705 ],\n",
       "         [0.06894972, 0.93105036],\n",
       "         [0.03937509, 0.96062493],\n",
       "         [0.0359875 , 0.96401244],\n",
       "         [0.04984921, 0.95015085],\n",
       "         [0.04473262, 0.95526737],\n",
       "         [0.8967626 , 0.10323742],\n",
       "         [0.04053862, 0.95946133]], dtype=float32)},\n",
       " 'pattern': {'y_true': array([0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "         1, 0, 0]),\n",
       "  'y_pred': array([[0.49949223, 0.50050783],\n",
       "         [0.45117423, 0.5488258 ],\n",
       "         [0.4531103 , 0.54688966],\n",
       "         [0.45384535, 0.5461547 ],\n",
       "         [0.49829653, 0.5017035 ],\n",
       "         [0.4521996 , 0.5478004 ],\n",
       "         [0.50085473, 0.49914518],\n",
       "         [0.5001255 , 0.49987453],\n",
       "         [0.44996324, 0.5500368 ],\n",
       "         [0.44995907, 0.5500409 ],\n",
       "         [0.4993178 , 0.5006823 ],\n",
       "         [0.49967656, 0.50032353],\n",
       "         [0.4492153 , 0.5507847 ],\n",
       "         [0.50013655, 0.4998635 ],\n",
       "         [0.4517922 , 0.54820776],\n",
       "         [0.45128965, 0.54871035],\n",
       "         [0.45035824, 0.5496417 ],\n",
       "         [0.501519  , 0.49848095],\n",
       "         [0.45175943, 0.54824054],\n",
       "         [0.50165063, 0.49834943],\n",
       "         [0.50029796, 0.49970198],\n",
       "         [0.49959987, 0.50040007],\n",
       "         [0.45061374, 0.54938626],\n",
       "         [0.49914587, 0.5008541 ],\n",
       "         [0.4998864 , 0.5001136 ]], dtype=float32)}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/Export Model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are happy with our training we can save (or export) our model, using the `save` method (or `export`).\n",
    "\n",
    "See the docs for the difference between `save` and `export`.\n",
    "\n",
    "We will need the saved model later to use in the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(folder='models/', model_id='TEXT_MODEL1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(folder='models/', model_id='TEXT_MODEL1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an image model and a text model, we can move to `Step4_train_ensemble_model`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
