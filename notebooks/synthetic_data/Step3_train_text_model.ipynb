{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the third step of this tutorial, we will train a text model. This step can be run in parallel with Step 2 (training the image model).\n",
    "\n",
    "This notebook was run on an AWS p3.2xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Octopod Text Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, BertTokenizer, get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for text, we use the MultiTaskLearner since we will only have one input, the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octopod import MultiTaskLearner, MultiDatasetLoader\n",
    "from octopod.text.dataset import OctopodTextDataset\n",
    "from octopod.text.models.multi_task_bert import BertForMultiTaskClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our Bert model, we need a tokenizer. We'll use the one from huggingface's `transformers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tok = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in train and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load in the csv's we created in Step 1.\n",
    "Remember to change the path if you stored your data somewhere other than the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_COLOR_DF = pd.read_csv('data/color_swatches/color_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_COLOR_DF = pd.read_csv('data/color_swatches/color_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATTERN_DF = pd.read_csv('data/pattern_swatches/pattern_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_PATTERN_DF = pd.read_csv('data/pattern_swatches/pattern_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will most likely have to alter this to however big your batches can be on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `OctopodTextDataSet` class to create train and valid datasets for each task.\n",
    "\n",
    "Check out the documentation for infomation about the `tokenizer` and `max_seq_length` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_train_dataset = OctopodTextDataset(\n",
    "    x=TRAIN_COLOR_DF['complex_color'],\n",
    "    y=TRAIN_COLOR_DF['simple_color_cat'],\n",
    "    tokenizer=bert_tok,\n",
    "    max_seq_length=max_seq_length\n",
    ")\n",
    "color_valid_dataset = OctopodTextDataset(\n",
    "    x=VALID_COLOR_DF['complex_color'],\n",
    "    y=VALID_COLOR_DF['simple_color_cat'],\n",
    "    tokenizer=bert_tok,\n",
    "    max_seq_length=max_seq_length\n",
    ")\n",
    "\n",
    "pattern_train_dataset = OctopodTextDataset(\n",
    "    x=TRAIN_PATTERN_DF['fake_text'],\n",
    "    y=TRAIN_PATTERN_DF['pattern_type_cat'],\n",
    "    tokenizer=bert_tok,\n",
    "    max_seq_length=max_seq_length\n",
    ")\n",
    "pattern_valid_dataset = OctopodTextDataset(\n",
    "    x=VALID_PATTERN_DF['fake_text'],\n",
    "    y=VALID_PATTERN_DF['pattern_type_cat'],\n",
    "    tokenizer=bert_tok,\n",
    "    max_seq_length=max_seq_length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then put the datasets into a dictionary of dataloaders.\n",
    "\n",
    "Each task is a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloaders_dict = {\n",
    "    'color': DataLoader(color_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2),\n",
    "    'pattern': DataLoader(pattern_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2),\n",
    "}\n",
    "valid_dataloaders_dict = {\n",
    "    'color': DataLoader(color_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2),\n",
    "    'pattern': DataLoader(pattern_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary of dataloaders is then put into an instance of the Octopod `MultiDatasetLoader` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLoader = MultiDatasetLoader(loader_dict=train_dataloaders_dict)\n",
    "len(TrainLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValidLoader = MultiDatasetLoader(loader_dict=valid_dataloaders_dict, shuffle=False)\n",
    "len(ValidLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a dictionary of the tasks and the number of unique values so that we can create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_task_dict = {\n",
    "    'color': TRAIN_COLOR_DF['simple_color_cat'].nunique(),\n",
    "    'pattern': TRAIN_PATTERN_DF['pattern_type_cat'].nunique(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'color': 2, 'pattern': 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_task_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model and Learner\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are completely new tasks so we use `new_task_dict`. If we had already trained a model on some tasks, we would use `pretrained_task_dict`.\n",
    "\n",
    "We are using the trained bert weights from the `transformers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMultiTaskClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    new_task_dict=new_task_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will likely need to explore different values in this section to find some that work\n",
    "for your particular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 1e-5\n",
    "num_total_steps = len(TrainLoader)\n",
    "num_warmup_steps = int(len(TrainLoader) * 0.1)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=True)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = MultiTaskLearner(model, TrainLoader, ValidLoader, new_task_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your model trains, you can see some output of how the model is performing overall and how it is doing on each individual task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>color_train_loss</th>\n",
       "      <th>color_val_loss</th>\n",
       "      <th>color_acc</th>\n",
       "      <th>pattern_train_loss</th>\n",
       "      <th>pattern_val_loss</th>\n",
       "      <th>pattern_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.673507</td>\n",
       "      <td>0.678065</td>\n",
       "      <td>0.669093</td>\n",
       "      <td>0.673634</td>\n",
       "      <td>0.633028</td>\n",
       "      <td>0.692575</td>\n",
       "      <td>0.697387</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.635844</td>\n",
       "      <td>0.681517</td>\n",
       "      <td>0.624756</td>\n",
       "      <td>0.677200</td>\n",
       "      <td>0.633028</td>\n",
       "      <td>0.683744</td>\n",
       "      <td>0.700339</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.648323</td>\n",
       "      <td>0.677732</td>\n",
       "      <td>0.630768</td>\n",
       "      <td>0.664646</td>\n",
       "      <td>0.633028</td>\n",
       "      <td>0.724161</td>\n",
       "      <td>0.734785</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.643457</td>\n",
       "      <td>0.668759</td>\n",
       "      <td>0.623312</td>\n",
       "      <td>0.663126</td>\n",
       "      <td>0.633028</td>\n",
       "      <td>0.730487</td>\n",
       "      <td>0.693319</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.647667</td>\n",
       "      <td>0.661604</td>\n",
       "      <td>0.633150</td>\n",
       "      <td>0.654076</td>\n",
       "      <td>0.633028</td>\n",
       "      <td>0.710381</td>\n",
       "      <td>0.694424</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.632600</td>\n",
       "      <td>0.654549</td>\n",
       "      <td>0.617980</td>\n",
       "      <td>0.645752</td>\n",
       "      <td>0.633028</td>\n",
       "      <td>0.695761</td>\n",
       "      <td>0.692903</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.606633</td>\n",
       "      <td>0.498171</td>\n",
       "      <td>0.582558</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.880734</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.694575</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.477038</td>\n",
       "      <td>0.467392</td>\n",
       "      <td>0.422161</td>\n",
       "      <td>0.417661</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.714107</td>\n",
       "      <td>0.684223</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.385024</td>\n",
       "      <td>0.422237</td>\n",
       "      <td>0.321107</td>\n",
       "      <td>0.353005</td>\n",
       "      <td>0.844037</td>\n",
       "      <td>0.661145</td>\n",
       "      <td>0.724087</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.339846</td>\n",
       "      <td>0.386559</td>\n",
       "      <td>0.244334</td>\n",
       "      <td>0.322320</td>\n",
       "      <td>0.862385</td>\n",
       "      <td>0.752454</td>\n",
       "      <td>0.666643</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 best model saved with loss of 0.38655938819718005\n"
     ]
    }
   ],
   "source": [
    "learn.fit(\n",
    "    num_epochs=10,\n",
    "    loss_function=loss_function,\n",
    "    scheduler=scheduler,\n",
    "    step_scheduler_on_batch=False,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    best_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate Model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a method on the learner called `get_val_preds`, which makes predictions on the validation data. You can then use this to analyze your model's performance in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = learn.get_val_preds(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'color': {'y_true': array([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "         0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "         1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "         1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
       "         0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 0., 1., 1., 1., 1.]),\n",
       "  'y_pred': array([[0.03190912, 0.96809083],\n",
       "         [0.03047537, 0.96952462],\n",
       "         [0.0298619 , 0.97013813],\n",
       "         [0.84294468, 0.15705533],\n",
       "         [0.03198458, 0.96801543],\n",
       "         [0.02479118, 0.97520882],\n",
       "         [0.02475239, 0.97524762],\n",
       "         [0.04119167, 0.9588083 ],\n",
       "         [0.18129022, 0.81870973],\n",
       "         [0.02601881, 0.9739812 ],\n",
       "         [0.84400207, 0.15599801],\n",
       "         [0.83692592, 0.16307409],\n",
       "         [0.03339685, 0.9666031 ],\n",
       "         [0.03127979, 0.96872014],\n",
       "         [0.8366527 , 0.16334729],\n",
       "         [0.83247709, 0.16752286],\n",
       "         [0.03202241, 0.96797758],\n",
       "         [0.84101802, 0.15898195],\n",
       "         [0.14269081, 0.85730922],\n",
       "         [0.03248619, 0.9675138 ],\n",
       "         [0.03109268, 0.96890736],\n",
       "         [0.23020719, 0.76979285],\n",
       "         [0.03279769, 0.96720225],\n",
       "         [0.03078921, 0.96921086],\n",
       "         [0.03733124, 0.96266878],\n",
       "         [0.84292477, 0.1570752 ],\n",
       "         [0.84234285, 0.15765712],\n",
       "         [0.84113413, 0.15886585],\n",
       "         [0.7270084 , 0.27299163],\n",
       "         [0.25985989, 0.74014008],\n",
       "         [0.84010381, 0.15989619],\n",
       "         [0.8447153 , 0.15528472],\n",
       "         [0.04694493, 0.95305508],\n",
       "         [0.84195346, 0.15804659],\n",
       "         [0.03275121, 0.96724874],\n",
       "         [0.03084796, 0.96915203],\n",
       "         [0.84297502, 0.15702499],\n",
       "         [0.30965662, 0.69034338],\n",
       "         [0.03605312, 0.96394688],\n",
       "         [0.8004837 , 0.19951633],\n",
       "         [0.14079504, 0.85920495],\n",
       "         [0.84185302, 0.15814696],\n",
       "         [0.03255345, 0.96744657],\n",
       "         [0.0322763 , 0.96772367],\n",
       "         [0.84436393, 0.15563606],\n",
       "         [0.83129805, 0.1687019 ],\n",
       "         [0.03004167, 0.96995831],\n",
       "         [0.03090402, 0.96909595],\n",
       "         [0.03906753, 0.96093249],\n",
       "         [0.84136844, 0.15863159],\n",
       "         [0.0311462 , 0.96885377],\n",
       "         [0.03062572, 0.96937424],\n",
       "         [0.16305272, 0.83694726],\n",
       "         [0.03156464, 0.96843529],\n",
       "         [0.03079152, 0.96920848],\n",
       "         [0.03186805, 0.96813196],\n",
       "         [0.03083474, 0.96916527],\n",
       "         [0.03095321, 0.96904683],\n",
       "         [0.03427756, 0.96572244],\n",
       "         [0.83693612, 0.16306387],\n",
       "         [0.03264763, 0.96735239],\n",
       "         [0.8420946 , 0.15790543],\n",
       "         [0.16876104, 0.83123893],\n",
       "         [0.83246762, 0.16753234],\n",
       "         [0.77791387, 0.22208606],\n",
       "         [0.84336829, 0.15663178],\n",
       "         [0.03256699, 0.96743304],\n",
       "         [0.03391774, 0.96608222],\n",
       "         [0.03260424, 0.96739578],\n",
       "         [0.84697002, 0.15303002],\n",
       "         [0.03054743, 0.96945256],\n",
       "         [0.84192508, 0.15807496],\n",
       "         [0.03420447, 0.96579552],\n",
       "         [0.11994105, 0.880059  ],\n",
       "         [0.07176869, 0.9282313 ],\n",
       "         [0.03175886, 0.96824116],\n",
       "         [0.84042484, 0.15957516],\n",
       "         [0.33281162, 0.66718835],\n",
       "         [0.83070952, 0.16929045],\n",
       "         [0.84111518, 0.1588849 ],\n",
       "         [0.04644317, 0.95355678],\n",
       "         [0.10348113, 0.89651889],\n",
       "         [0.03870091, 0.96129906],\n",
       "         [0.78203601, 0.21796399],\n",
       "         [0.84045178, 0.15954825],\n",
       "         [0.84236908, 0.15763095],\n",
       "         [0.82736701, 0.17263304],\n",
       "         [0.07625858, 0.92374146],\n",
       "         [0.83166027, 0.1683397 ],\n",
       "         [0.03163524, 0.96836478],\n",
       "         [0.03017012, 0.96982992],\n",
       "         [0.84331113, 0.15668888],\n",
       "         [0.84449995, 0.15550005],\n",
       "         [0.76415551, 0.23584449],\n",
       "         [0.03144052, 0.96855944],\n",
       "         [0.83911574, 0.16088431],\n",
       "         [0.03016172, 0.9698382 ],\n",
       "         [0.03057696, 0.96942312],\n",
       "         [0.03293554, 0.96706444],\n",
       "         [0.03175198, 0.96824795],\n",
       "         [0.03407915, 0.96592081],\n",
       "         [0.84176075, 0.15823922],\n",
       "         [0.03127352, 0.96872652],\n",
       "         [0.03119986, 0.96880013],\n",
       "         [0.25681642, 0.74318361],\n",
       "         [0.03040027, 0.96959966],\n",
       "         [0.09397424, 0.90602577],\n",
       "         [0.03131936, 0.96868068],\n",
       "         [0.03130708, 0.96869296]])},\n",
       " 'pattern': {'y_true': array([0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
       "         0., 1., 0., 0., 0., 1., 0., 0.]),\n",
       "  'y_pred': array([[0.52685183, 0.47314817],\n",
       "         [0.49928561, 0.50071436],\n",
       "         [0.49906701, 0.50093299],\n",
       "         [0.5027591 , 0.49724093],\n",
       "         [0.52630663, 0.47369337],\n",
       "         [0.50168735, 0.49831268],\n",
       "         [0.52727675, 0.47272331],\n",
       "         [0.52650422, 0.47349578],\n",
       "         [0.50290996, 0.49708998],\n",
       "         [0.50080746, 0.49919251],\n",
       "         [0.52756286, 0.47243711],\n",
       "         [0.52780378, 0.47219622],\n",
       "         [0.50052941, 0.49947059],\n",
       "         [0.52750456, 0.47249538],\n",
       "         [0.50146961, 0.49853036],\n",
       "         [0.49952111, 0.50047892],\n",
       "         [0.5000574 , 0.49994263],\n",
       "         [0.52678418, 0.47321582],\n",
       "         [0.50240761, 0.49759245],\n",
       "         [0.52786356, 0.47213644],\n",
       "         [0.52595979, 0.47404021],\n",
       "         [0.52713048, 0.47286949],\n",
       "         [0.50093651, 0.49906349],\n",
       "         [0.52585828, 0.47414175],\n",
       "         [0.52856642, 0.47143355]])}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/Export Model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are happy with our training we can save (or export) our model, using the `save` method (or `export`).\n",
    "\n",
    "See the docs for the difference between `save` and `export`.\n",
    "\n",
    "We will need the saved model later to use in the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(folder='models/', model_id='TEXT_MODEL1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(folder='models/', model_id='TEXT_MODEL1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an image model and a text model, we can move to `Step4_train_ensemble_model`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
