{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the second step of this tutorial, we will train an image model. This step can be run in parallel with Step 3 (training the text model).\n",
    "\n",
    "This notebook was run on an AWS p3.2xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Octopod Image Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for images, we use the MultiInputMultiTaskLearner since we will send in the full image and a center crop of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octopod import MultiInputMultiTaskLearner, MultiDatasetLoader\n",
    "from octopod.vision.dataset import OctopodImageDataset\n",
    "from octopod.vision.models import ResnetForMultiTaskClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in train and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load in the csv's we created in Step 1.\n",
    "Remember to change the path if you stored your data somewhere other than the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_COLOR_DF = pd.read_csv('data/color_swatches/color_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_COLOR_DF = pd.read_csv('data/color_swatches/color_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATTERN_DF = pd.read_csv('data/pattern_swatches/pattern_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_PATTERN_DF = pd.read_csv('data/pattern_swatches/pattern_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will most likely have to alter this to however big your batches can be on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `OctopodImageDataSet` class to create train and valid datasets for each task.\n",
    "\n",
    "Check out the documentation for infomation about the transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_train_dataset = OctopodImageDataset(\n",
    "    x=TRAIN_COLOR_DF['image_locs'],\n",
    "    y=TRAIN_COLOR_DF['simple_color_cat'],\n",
    "    transform='train',\n",
    "    crop_transform='train'\n",
    ")\n",
    "color_valid_dataset = OctopodImageDataset(\n",
    "    x=VALID_COLOR_DF['image_locs'],\n",
    "    y=VALID_COLOR_DF['simple_color_cat'],\n",
    "    transform='val',\n",
    "    crop_transform='val'\n",
    ")\n",
    "\n",
    "pattern_train_dataset = OctopodImageDataset(\n",
    "    x=TRAIN_PATTERN_DF['image_locs'],\n",
    "    y=TRAIN_PATTERN_DF['pattern_type_cat'],\n",
    "    transform='train',\n",
    "    crop_transform='train'\n",
    ")\n",
    "pattern_valid_dataset = OctopodImageDataset(\n",
    "    x=VALID_PATTERN_DF['image_locs'],\n",
    "    y=VALID_PATTERN_DF['pattern_type_cat'],\n",
    "    transform='val',\n",
    "    crop_transform='val'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then put the datasets into a dictionary of dataloaders.\n",
    "\n",
    "Each task is a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloaders_dict = {\n",
    "    'color': DataLoader(color_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2),\n",
    "    'pattern': DataLoader(pattern_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2),\n",
    "}\n",
    "valid_dataloaders_dict = {\n",
    "    'color': DataLoader(color_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=8),\n",
    "    'pattern': DataLoader(pattern_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=8),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary of dataloaders is then put into an instance of the Octopod `MultiDatasetLoader` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLoader = MultiDatasetLoader(loader_dict=train_dataloaders_dict)\n",
    "len(TrainLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValidLoader = MultiDatasetLoader(loader_dict=valid_dataloaders_dict, shuffle=False)\n",
    "len(ValidLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a dictionary of the tasks and the number of unique values so that we can create our model. This is a `new_task_dict` because we are training new tasks from scratch, but we could potentially have a mix of new and pretrained tasks. See the Octopod documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_task_dict = {\n",
    "    'color': TRAIN_COLOR_DF['simple_color_cat'].nunique(),\n",
    "    'pattern': TRAIN_PATTERN_DF['pattern_type_cat'].nunique(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'color': 2, 'pattern': 2}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_task_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model and Learner\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are completely new tasks so we use `new_task_dict`. If we had already trained a model on some tasks, we would use `pretrained_task_dict`.\n",
    "\n",
    "And since these are new tasks, we set `load_pretrained_renset=True` to use the weights from Torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetForMultiTaskClassification(\n",
    "    new_task_dict=new_task_dict,\n",
    "    load_pretrained_resnet=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will likely need to explore different values in this section to find some that work for your particular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_last = 1e-2\n",
    "lr_main = 1e-4\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.resnet.parameters(), 'lr': lr_main},\n",
    "    {'params': model.dense_layers.parameters(), 'lr': lr_last},\n",
    "    {'params': model.new_classifiers.parameters(), 'lr': lr_last},\n",
    "    \n",
    "])\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size= 4, gamma= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function_dict = {'color': 'categorical_cross_entropy', 'pattern': 'categorical_cross_entropy'}\n",
    "metric_function_dict = {'color': 'multi_class_acc', 'pattern': 'multi_class_acc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = MultiInputMultiTaskLearner(model, TrainLoader, ValidLoader, new_task_dict, loss_function_dict, metric_function_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your model trains, you can see some output of how the model is performing overall and how it is doing on each individual task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>color_train_loss</th>\n",
       "      <th>color_val_loss</th>\n",
       "      <th>color_multi_class_accuracy</th>\n",
       "      <th>pattern_train_loss</th>\n",
       "      <th>pattern_val_loss</th>\n",
       "      <th>pattern_multi_class_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.527560</td>\n",
       "      <td>0.025808</td>\n",
       "      <td>0.455579</td>\n",
       "      <td>0.018895</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.837555</td>\n",
       "      <td>0.055673</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.316734</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.220964</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.729182</td>\n",
       "      <td>0.042902</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.242027</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.173330</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.537883</td>\n",
       "      <td>0.038504</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.182427</td>\n",
       "      <td>0.014214</td>\n",
       "      <td>0.168406</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.242809</td>\n",
       "      <td>0.058019</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.153758</td>\n",
       "      <td>0.012729</td>\n",
       "      <td>0.124627</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.279215</td>\n",
       "      <td>0.056759</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128590</td>\n",
       "      <td>0.012524</td>\n",
       "      <td>0.110009</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.208611</td>\n",
       "      <td>0.054095</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.098957</td>\n",
       "      <td>0.015342</td>\n",
       "      <td>0.087208</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.149558</td>\n",
       "      <td>0.061024</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.095887</td>\n",
       "      <td>0.011757</td>\n",
       "      <td>0.081883</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.156199</td>\n",
       "      <td>0.052724</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.101653</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.100016</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.108702</td>\n",
       "      <td>0.036416</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.095422</td>\n",
       "      <td>0.011112</td>\n",
       "      <td>0.090029</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.118647</td>\n",
       "      <td>0.046202</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 best model saved with loss of 0.00905553251504898\n"
     ]
    }
   ],
   "source": [
    "learn.fit(\n",
    "    num_epochs=10,\n",
    "    scheduler=exp_lr_scheduler,\n",
    "    step_scheduler_on_batch=False,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    best_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the above cell and see an error like: \n",
    "\n",
    "```python\n",
    "RuntimeError: DataLoader worker (pid X) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.\n",
    "```\n",
    "\n",
    "Try lowering the `num_workers` to `0` for each `DataLoader` in `train_dataloaders_dict` and `valid_dataloaders_dict`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a method on the learner called `get_val_preds`, which makes predictions on the validation data. You can then use this to analyze your model's performance in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_dict = learn.get_val_preds(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'color': {'y_true': array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "         0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "         1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "         0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]),\n",
       "  'y_pred': array([[8.63048699e-05, 9.99913692e-01],\n",
       "         [1.23549262e-02, 9.87645090e-01],\n",
       "         [1.56733469e-04, 9.99843240e-01],\n",
       "         [3.93248983e-02, 9.60675061e-01],\n",
       "         [3.09351861e-04, 9.99690652e-01],\n",
       "         [1.47890067e-02, 9.85211015e-01],\n",
       "         [2.85775837e-04, 9.99714196e-01],\n",
       "         [1.99814723e-03, 9.98001873e-01],\n",
       "         [9.55912054e-01, 4.40879054e-02],\n",
       "         [6.96805291e-05, 9.99930263e-01],\n",
       "         [8.37490857e-01, 1.62509143e-01],\n",
       "         [5.89722931e-01, 4.10277128e-01],\n",
       "         [6.11390977e-04, 9.99388576e-01],\n",
       "         [1.05856903e-04, 9.99894142e-01],\n",
       "         [6.94748342e-01, 3.05251658e-01],\n",
       "         [2.53077527e-03, 9.97469187e-01],\n",
       "         [2.39060703e-03, 9.97609377e-01],\n",
       "         [1.00310671e-03, 9.98996913e-01],\n",
       "         [8.08612385e-05, 9.99919176e-01],\n",
       "         [4.54515934e-01, 5.45484066e-01],\n",
       "         [5.07033383e-03, 9.94929671e-01],\n",
       "         [8.73051584e-01, 1.26948446e-01],\n",
       "         [8.83152366e-01, 1.16847612e-01],\n",
       "         [6.88235164e-01, 3.11764807e-01],\n",
       "         [2.54926886e-02, 9.74507332e-01],\n",
       "         [2.48054457e-05, 9.99975204e-01],\n",
       "         [4.65903031e-05, 9.99953389e-01],\n",
       "         [4.49879244e-02, 9.55012023e-01],\n",
       "         [5.79808326e-03, 9.94201958e-01],\n",
       "         [8.94894421e-01, 1.05105609e-01],\n",
       "         [5.98312262e-03, 9.94016886e-01],\n",
       "         [9.87334490e-01, 1.26655642e-02],\n",
       "         [1.92805729e-03, 9.98071909e-01],\n",
       "         [7.23160326e-01, 2.76839644e-01],\n",
       "         [8.43540251e-01, 1.56459719e-01],\n",
       "         [4.85333672e-04, 9.99514699e-01],\n",
       "         [9.43971276e-02, 9.05602932e-01],\n",
       "         [5.37784755e-01, 4.62215215e-01],\n",
       "         [3.61026317e-01, 6.38973594e-01],\n",
       "         [4.69887775e-04, 9.99530077e-01],\n",
       "         [1.47961453e-03, 9.98520434e-01],\n",
       "         [7.49744650e-04, 9.99250233e-01],\n",
       "         [9.05039847e-01, 9.49601308e-02],\n",
       "         [5.52781336e-02, 9.44721878e-01],\n",
       "         [8.39099944e-01, 1.60900012e-01],\n",
       "         [6.99707091e-01, 3.00292879e-01],\n",
       "         [9.26809967e-01, 7.31900111e-02],\n",
       "         [9.90666304e-05, 9.99900937e-01],\n",
       "         [1.64599405e-05, 9.99983549e-01],\n",
       "         [1.09389937e-02, 9.89060998e-01],\n",
       "         [2.46983866e-04, 9.99753058e-01],\n",
       "         [1.24861926e-01, 8.75138044e-01],\n",
       "         [7.20717728e-01, 2.79282331e-01],\n",
       "         [3.30402656e-03, 9.96695995e-01],\n",
       "         [7.47093232e-04, 9.99252856e-01],\n",
       "         [2.18205795e-01, 7.81794190e-01],\n",
       "         [5.35635081e-05, 9.99946475e-01],\n",
       "         [5.37838961e-04, 9.99462187e-01],\n",
       "         [1.35858217e-03, 9.98641431e-01],\n",
       "         [6.94129884e-01, 3.05870175e-01],\n",
       "         [8.76071513e-01, 1.23928539e-01],\n",
       "         [6.68398058e-03, 9.93315995e-01],\n",
       "         [1.08173280e-03, 9.98918295e-01],\n",
       "         [1.59980834e-01, 8.40019166e-01],\n",
       "         [8.48955393e-01, 1.51044667e-01],\n",
       "         [9.14992273e-01, 8.50077644e-02],\n",
       "         [2.04279236e-02, 9.79572117e-01],\n",
       "         [4.56501320e-02, 9.54349816e-01],\n",
       "         [3.36532155e-03, 9.96634662e-01],\n",
       "         [3.32686905e-05, 9.99966741e-01],\n",
       "         [9.17130172e-01, 8.28698501e-02],\n",
       "         [7.39679277e-01, 2.60320723e-01],\n",
       "         [4.81011299e-03, 9.95189905e-01],\n",
       "         [8.90977740e-01, 1.09022230e-01],\n",
       "         [8.81023228e-01, 1.18976817e-01],\n",
       "         [6.39740527e-02, 9.36025918e-01],\n",
       "         [1.11209035e-01, 8.88790965e-01],\n",
       "         [5.58818877e-03, 9.94411767e-01],\n",
       "         [8.97548914e-01, 1.02451086e-01],\n",
       "         [5.99833667e-01, 4.00166363e-01],\n",
       "         [5.40226281e-01, 4.59773749e-01],\n",
       "         [2.15130329e-01, 7.84869611e-01],\n",
       "         [5.03148794e-01, 4.96851206e-01],\n",
       "         [1.29998952e-01, 8.70001078e-01],\n",
       "         [2.87369796e-04, 9.99712646e-01],\n",
       "         [4.81691939e-04, 9.99518275e-01],\n",
       "         [2.05576350e-03, 9.97944176e-01],\n",
       "         [4.31515556e-03, 9.95684862e-01],\n",
       "         [7.78358161e-01, 2.21641809e-01],\n",
       "         [2.02665920e-03, 9.97973382e-01],\n",
       "         [7.33409405e-01, 2.66590565e-01],\n",
       "         [9.36253309e-01, 6.37467057e-02],\n",
       "         [8.38608205e-01, 1.61391765e-01],\n",
       "         [1.02600053e-01, 8.97400022e-01],\n",
       "         [4.52008191e-03, 9.95479941e-01],\n",
       "         [9.49800014e-01, 5.01999930e-02],\n",
       "         [2.24152906e-03, 9.97758389e-01],\n",
       "         [8.58428776e-01, 1.41571209e-01],\n",
       "         [5.24581969e-01, 4.75418031e-01],\n",
       "         [8.14884007e-01, 1.85116053e-01],\n",
       "         [1.31571910e-03, 9.98684227e-01],\n",
       "         [8.98087048e-04, 9.99101996e-01],\n",
       "         [5.81895793e-03, 9.94180977e-01],\n",
       "         [4.27449813e-05, 9.99957204e-01],\n",
       "         [2.73211509e-01, 7.26788402e-01],\n",
       "         [8.46899487e-03, 9.91531014e-01],\n",
       "         [8.97803307e-01, 1.02196679e-01],\n",
       "         [3.67403426e-03, 9.96325910e-01]], dtype=float32)},\n",
       " 'pattern': {'y_true': array([0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "         1, 0, 0]),\n",
       "  'y_pred': array([[6.6915607e-01, 3.3084393e-01],\n",
       "         [5.6399992e-03, 9.9436003e-01],\n",
       "         [2.5414254e-03, 9.9745864e-01],\n",
       "         [1.1238403e-04, 9.9988759e-01],\n",
       "         [1.0885979e-01, 8.9114028e-01],\n",
       "         [1.9496094e-05, 9.9998045e-01],\n",
       "         [8.8108170e-01, 1.1891826e-01],\n",
       "         [1.5006079e-01, 8.4993923e-01],\n",
       "         [6.2785293e-05, 9.9993718e-01],\n",
       "         [1.7755931e-04, 9.9982244e-01],\n",
       "         [1.1462306e-02, 9.8853767e-01],\n",
       "         [1.5272751e-01, 8.4727252e-01],\n",
       "         [1.2808132e-03, 9.9871922e-01],\n",
       "         [8.8393939e-01, 1.1606055e-01],\n",
       "         [1.2803663e-04, 9.9987197e-01],\n",
       "         [2.5190279e-02, 9.7480971e-01],\n",
       "         [1.0871959e-04, 9.9989128e-01],\n",
       "         [1.4688773e-01, 8.5311222e-01],\n",
       "         [2.0587493e-03, 9.9794120e-01],\n",
       "         [5.2660751e-01, 4.7339246e-01],\n",
       "         [3.3146361e-01, 6.6853642e-01],\n",
       "         [3.1141924e-02, 9.6885812e-01],\n",
       "         [4.6899135e-05, 9.9995315e-01],\n",
       "         [2.5645885e-01, 7.4354118e-01],\n",
       "         [4.4375639e-02, 9.5562434e-01]], dtype=float32)}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/Export Model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are happy with our training we can save (or export) our model, using the `save` method (or `export`).\n",
    "\n",
    "See the docs for the difference between `save` and `export`.\n",
    "\n",
    "We will need the saved model later to use in the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(folder='models/', model_id='IMAGE_MODEL1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(folder='models/', model_id='IMAGE_MODEL1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an image model, we can move to `Step3_train_text_model`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
