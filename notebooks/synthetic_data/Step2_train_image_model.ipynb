{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the second step of this tutorial, we will train an image model. This step can be run in parallel with Step 3 (training the text model).\n",
    "\n",
    "This notebook was run on an AWS p3.2xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tonks Image Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for images, we use the MultiInputMultiTaskLearner since we will send in the full image and a center crop of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tonks import MultiInputMultiTaskLearner, MultiDatasetLoader\n",
    "from tonks.vision.dataset import TonksImageDataset\n",
    "from tonks.vision.models import ResnetForMultiTaskClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in train and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load in the csv's we created in Step 1.\n",
    "Remember to change the path if you stored your data somewhere other than the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_COLOR_DF = pd.read_csv('data/color_swatches/color_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_COLOR_DF = pd.read_csv('data/color_swatches/color_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATTERN_DF = pd.read_csv('data/pattern_swatches/pattern_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_PATTERN_DF = pd.read_csv('data/pattern_swatches/pattern_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will most likely have to alter this to however big your batches can be on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `TonksImageDataSet` class to create train and valid datasets for each task.\n",
    "\n",
    "Check out the documentation for infomation about the transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_train_dataset = TonksImageDataset(\n",
    "    x=TRAIN_COLOR_DF['image_locs'],\n",
    "    y=TRAIN_COLOR_DF['simple_color_cat'],\n",
    "    transform='train',\n",
    "    crop_transform='train'\n",
    ")\n",
    "color_valid_dataset = TonksImageDataset(\n",
    "    x=VALID_COLOR_DF['image_locs'],\n",
    "    y=VALID_COLOR_DF['simple_color_cat'],\n",
    "    transform='val',\n",
    "    crop_transform='val'\n",
    ")\n",
    "\n",
    "pattern_train_dataset = TonksImageDataset(\n",
    "    x=TRAIN_PATTERN_DF['image_locs'],\n",
    "    y=TRAIN_PATTERN_DF['pattern_type_cat'],\n",
    "    transform='train',\n",
    "    crop_transform='train'\n",
    ")\n",
    "pattern_valid_dataset = TonksImageDataset(\n",
    "    x=VALID_PATTERN_DF['image_locs'],\n",
    "    y=VALID_PATTERN_DF['pattern_type_cat'],\n",
    "    transform='val',\n",
    "    crop_transform='val'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then put the datasets into a dictionary of dataloaders.\n",
    "\n",
    "Each task is a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloaders_dict = {\n",
    "    'color': DataLoader(color_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2),\n",
    "    'pattern': DataLoader(pattern_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2),\n",
    "}\n",
    "valid_dataloaders_dict = {\n",
    "    'color': DataLoader(color_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=8),\n",
    "    'pattern': DataLoader(pattern_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=8),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary of dataloaders is then put into an instance of the Tonks `MultiDatasetLoader` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLoader = MultiDatasetLoader(loader_dict=train_dataloaders_dict)\n",
    "len(TrainLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValidLoader = MultiDatasetLoader(loader_dict=valid_dataloaders_dict, shuffle=False)\n",
    "len(ValidLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a dictionary of the tasks and the number of unique values so that we can create our model. This is a `new_task_dict` because we are training new tasks from scratch, but we could potentially have a mix of new and pretrained tasks. See the Tonks documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_task_dict = {\n",
    "    'color': TRAIN_COLOR_DF['simple_color_cat'].nunique(),\n",
    "    'pattern': TRAIN_PATTERN_DF['pattern_type_cat'].nunique(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'color': 2, 'pattern': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_task_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model and Learner\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are completely new tasks so we use `new_task_dict`. If we had already trained a model on some tasks, we would use `pretrained_task_dict`.\n",
    "\n",
    "And since these are new tasks, we set `load_pretrained_renset=True` to use the weights from Torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetForMultiTaskClassification(\n",
    "    new_task_dict=new_task_dict,\n",
    "    load_pretrained_resnet=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will likely need to explore different values in this section to find some that work for your particular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "lr_last = 1e-2\n",
    "lr_main = 1e-4\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.resnet.parameters(), 'lr': lr_main},\n",
    "    {'params': model.dense_layers.parameters(), 'lr': lr_last},\n",
    "    {'params': model.new_classifiers.parameters(), 'lr': lr_last},\n",
    "    \n",
    "])\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size= 4, gamma= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = MultiInputMultiTaskLearner(model, TrainLoader, ValidLoader, new_task_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your model trains, you can see some output of how the model is performing overall and how it is doing on each individual task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>color_train_loss</th>\n",
       "      <th>color_val_loss</th>\n",
       "      <th>color_acc</th>\n",
       "      <th>pattern_train_loss</th>\n",
       "      <th>pattern_val_loss</th>\n",
       "      <th>pattern_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.477539</td>\n",
       "      <td>1.950549</td>\n",
       "      <td>0.393019</td>\n",
       "      <td>0.956634</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>0.842661</td>\n",
       "      <td>6.284015</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.620837</td>\n",
       "      <td>1.322428</td>\n",
       "      <td>0.291730</td>\n",
       "      <td>0.273103</td>\n",
       "      <td>0.889908</td>\n",
       "      <td>2.042579</td>\n",
       "      <td>5.897488</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.340648</td>\n",
       "      <td>1.139325</td>\n",
       "      <td>0.190167</td>\n",
       "      <td>0.651669</td>\n",
       "      <td>0.605505</td>\n",
       "      <td>0.990727</td>\n",
       "      <td>3.265508</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.475544</td>\n",
       "      <td>0.343081</td>\n",
       "      <td>0.242980</td>\n",
       "      <td>0.210864</td>\n",
       "      <td>0.926606</td>\n",
       "      <td>1.480220</td>\n",
       "      <td>0.919548</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.245107</td>\n",
       "      <td>0.381223</td>\n",
       "      <td>0.153973</td>\n",
       "      <td>0.215807</td>\n",
       "      <td>0.926606</td>\n",
       "      <td>0.638806</td>\n",
       "      <td>1.102434</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.267711</td>\n",
       "      <td>0.218120</td>\n",
       "      <td>0.177266</td>\n",
       "      <td>0.158958</td>\n",
       "      <td>0.963303</td>\n",
       "      <td>0.658432</td>\n",
       "      <td>0.476063</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.187381</td>\n",
       "      <td>0.293359</td>\n",
       "      <td>0.110614</td>\n",
       "      <td>0.254613</td>\n",
       "      <td>0.899083</td>\n",
       "      <td>0.519016</td>\n",
       "      <td>0.462289</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.192692</td>\n",
       "      <td>0.281958</td>\n",
       "      <td>0.110441</td>\n",
       "      <td>0.223454</td>\n",
       "      <td>0.899083</td>\n",
       "      <td>0.548017</td>\n",
       "      <td>0.537036</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.167040</td>\n",
       "      <td>0.391435</td>\n",
       "      <td>0.095955</td>\n",
       "      <td>0.333345</td>\n",
       "      <td>0.871560</td>\n",
       "      <td>0.474127</td>\n",
       "      <td>0.644704</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119068</td>\n",
       "      <td>0.386770</td>\n",
       "      <td>0.080910</td>\n",
       "      <td>0.332941</td>\n",
       "      <td>0.862385</td>\n",
       "      <td>0.283910</td>\n",
       "      <td>0.621464</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 best model saved with loss of 0.21811976695238655\n"
     ]
    }
   ],
   "source": [
    "learn.fit(\n",
    "    num_epochs=10,\n",
    "    loss_function=loss_function,\n",
    "    scheduler=exp_lr_scheduler,\n",
    "    step_scheduler_on_batch=False,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    best_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a method on the learner called `get_val_preds`, which makes predictions on the validation data. You can then use this to analyze your model's performance in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_dict = learn.get_val_preds(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'color': {'y_true': array([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "         0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "         1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "         1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
       "         0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 0., 1., 1., 1., 1.]),\n",
       "  'y_pred': array([[2.45792523e-01, 7.54207492e-01],\n",
       "         [2.71383077e-01, 7.28616953e-01],\n",
       "         [2.12360248e-01, 7.87639737e-01],\n",
       "         [9.95112598e-01, 4.88745281e-03],\n",
       "         [1.20328076e-01, 8.79671931e-01],\n",
       "         [2.19809279e-01, 7.80190766e-01],\n",
       "         [1.63681567e-01, 8.36318374e-01],\n",
       "         [1.44761562e-01, 8.55238438e-01],\n",
       "         [1.51116133e-01, 8.48883808e-01],\n",
       "         [1.44175127e-01, 8.55824888e-01],\n",
       "         [9.76195037e-01, 2.38049980e-02],\n",
       "         [9.96692419e-01, 3.30754113e-03],\n",
       "         [5.81348501e-03, 9.94186521e-01],\n",
       "         [1.84676483e-01, 8.15323532e-01],\n",
       "         [9.90133405e-01, 9.86661203e-03],\n",
       "         [9.59128976e-01, 4.08710353e-02],\n",
       "         [1.53327271e-01, 8.46672714e-01],\n",
       "         [9.99048889e-01, 9.51106427e-04],\n",
       "         [8.98086369e-01, 1.01913624e-01],\n",
       "         [1.62022352e-01, 8.37977648e-01],\n",
       "         [1.45269409e-01, 8.54730606e-01],\n",
       "         [1.31477788e-01, 8.68522227e-01],\n",
       "         [4.18987265e-03, 9.95810151e-01],\n",
       "         [1.46469355e-01, 8.53530586e-01],\n",
       "         [1.71147153e-01, 8.28852832e-01],\n",
       "         [9.99812424e-01, 1.87650832e-04],\n",
       "         [9.07667160e-01, 9.23329070e-02],\n",
       "         [3.47633094e-01, 6.52366936e-01],\n",
       "         [5.64336479e-01, 4.35663551e-01],\n",
       "         [9.91531909e-01, 8.46811850e-03],\n",
       "         [6.67612016e-01, 3.32387954e-01],\n",
       "         [1.68891162e-01, 8.31108868e-01],\n",
       "         [1.32674366e-01, 8.67325664e-01],\n",
       "         [9.94836688e-01, 5.16339391e-03],\n",
       "         [1.52839959e-01, 8.47160101e-01],\n",
       "         [1.18474290e-01, 8.81525755e-01],\n",
       "         [9.99888778e-01, 1.11170331e-04],\n",
       "         [6.82799280e-01, 3.17200691e-01],\n",
       "         [9.74537507e-02, 9.02546287e-01],\n",
       "         [3.17148417e-01, 6.82851613e-01],\n",
       "         [9.42727849e-02, 9.05727208e-01],\n",
       "         [4.23749268e-01, 5.76250672e-01],\n",
       "         [1.32875323e-01, 8.67124736e-01],\n",
       "         [1.30795851e-01, 8.69204104e-01],\n",
       "         [9.94230866e-01, 5.76914521e-03],\n",
       "         [9.86645937e-01, 1.33540425e-02],\n",
       "         [9.99805391e-01, 1.94651409e-04],\n",
       "         [1.50131747e-01, 8.49868298e-01],\n",
       "         [9.62952618e-04, 9.99037027e-01],\n",
       "         [9.98536587e-01, 1.46342069e-03],\n",
       "         [1.38058409e-01, 8.61941636e-01],\n",
       "         [1.23353722e-03, 9.98766541e-01],\n",
       "         [9.95170414e-01, 4.82958416e-03],\n",
       "         [1.20479360e-01, 8.79520714e-01],\n",
       "         [1.40067145e-01, 8.59932840e-01],\n",
       "         [1.76602378e-01, 8.23397636e-01],\n",
       "         [3.32037162e-04, 9.99668002e-01],\n",
       "         [2.93180201e-04, 9.99706805e-01],\n",
       "         [1.81776181e-01, 8.18223834e-01],\n",
       "         [9.35278654e-01, 6.47212863e-02],\n",
       "         [5.49747407e-01, 4.50252533e-01],\n",
       "         [9.98788178e-01, 1.21188571e-03],\n",
       "         [9.10741743e-03, 9.90892529e-01],\n",
       "         [9.99512911e-01, 4.87144775e-04],\n",
       "         [2.04480439e-01, 7.95519531e-01],\n",
       "         [9.99885440e-01, 1.14552604e-04],\n",
       "         [1.41189024e-01, 8.58810961e-01],\n",
       "         [1.24276288e-01, 8.75723660e-01],\n",
       "         [1.57912995e-03, 9.98420835e-01],\n",
       "         [9.97029126e-01, 2.97093368e-03],\n",
       "         [1.13253877e-03, 9.98867512e-01],\n",
       "         [9.72632289e-01, 2.73677018e-02],\n",
       "         [5.68993203e-02, 9.43100691e-01],\n",
       "         [1.40101910e-01, 8.59898031e-01],\n",
       "         [1.72483400e-01, 8.27516615e-01],\n",
       "         [1.22072771e-01, 8.77927244e-01],\n",
       "         [9.74894702e-01, 2.51053516e-02],\n",
       "         [9.99957681e-01, 4.22989724e-05],\n",
       "         [9.93023872e-01, 6.97613228e-03],\n",
       "         [4.01593387e-01, 5.98406613e-01],\n",
       "         [1.39849335e-01, 8.60150635e-01],\n",
       "         [2.13186219e-01, 7.86813796e-01],\n",
       "         [3.21577042e-01, 6.78422987e-01],\n",
       "         [9.94909823e-01, 5.09023713e-03],\n",
       "         [9.98590767e-01, 1.40915276e-03],\n",
       "         [9.95804727e-01, 4.19535162e-03],\n",
       "         [3.16419750e-01, 6.83580220e-01],\n",
       "         [1.51659781e-03, 9.98483479e-01],\n",
       "         [9.98366296e-01, 1.63373910e-03],\n",
       "         [1.21431768e-01, 8.78568232e-01],\n",
       "         [1.11519076e-01, 8.88480961e-01],\n",
       "         [9.99631047e-01, 3.68935172e-04],\n",
       "         [9.96017754e-01, 3.98223056e-03],\n",
       "         [1.23282053e-01, 8.76717925e-01],\n",
       "         [1.30617633e-01, 8.69382381e-01],\n",
       "         [9.99785602e-01, 2.14401662e-04],\n",
       "         [1.44894436e-01, 8.55105579e-01],\n",
       "         [6.18161110e-04, 9.99381781e-01],\n",
       "         [1.66326493e-01, 8.33673537e-01],\n",
       "         [1.41397119e-01, 8.58602941e-01],\n",
       "         [2.47418210e-01, 7.52581835e-01],\n",
       "         [8.65299881e-01, 1.34700149e-01],\n",
       "         [1.33474261e-01, 8.66525769e-01],\n",
       "         [1.35995314e-01, 8.64004731e-01],\n",
       "         [2.41500646e-01, 7.58499384e-01],\n",
       "         [1.36691645e-01, 8.63308311e-01],\n",
       "         [2.06297830e-01, 7.93702185e-01],\n",
       "         [1.18347779e-01, 8.81652236e-01],\n",
       "         [1.61190748e-01, 8.38809192e-01]])},\n",
       " 'pattern': {'y_true': array([0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
       "         0., 1., 0., 0., 0., 1., 0., 0.]),\n",
       "  'y_pred': array([[0.33828813, 0.66171193],\n",
       "         [0.03545213, 0.96454787],\n",
       "         [0.01112085, 0.98887908],\n",
       "         [0.54421604, 0.45578399],\n",
       "         [0.29674065, 0.70325935],\n",
       "         [0.00127937, 0.99872059],\n",
       "         [0.98070657, 0.01929339],\n",
       "         [0.45726776, 0.54273224],\n",
       "         [0.16562167, 0.83437836],\n",
       "         [0.30097303, 0.69902694],\n",
       "         [0.84111261, 0.15888742],\n",
       "         [0.38896143, 0.61103857],\n",
       "         [0.10020804, 0.8997919 ],\n",
       "         [0.93013823, 0.06986175],\n",
       "         [0.23928419, 0.76071578],\n",
       "         [0.00387942, 0.99612051],\n",
       "         [0.35038379, 0.64961618],\n",
       "         [0.46917829, 0.53082168],\n",
       "         [0.21552786, 0.78447217],\n",
       "         [0.90273666, 0.09726331],\n",
       "         [0.04419063, 0.95580935],\n",
       "         [0.81585288, 0.18414718],\n",
       "         [0.17571534, 0.82428467],\n",
       "         [0.80120689, 0.19879314],\n",
       "         [0.55773604, 0.44226399]])}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/Export Model\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are happy with our training we can save (or export) our model, using the `save` method (or `export`).\n",
    "\n",
    "See the docs for the difference between `save` and `export`.\n",
    "\n",
    "We will need the saved model later to use in the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(folder='models/', model_id='IMAGE_MODEL1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(folder='models/', model_id='IMAGE_MODEL1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an image model, we can move to `Step3_train_text_model`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
